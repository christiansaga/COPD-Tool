{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3be7f4ca0fe9a7ab",
   "metadata": {},
   "source": [
    "# COPD Hospital Admission Prediction Project\n",
    "\n",
    "This project's goal is to predict the likelihood of hospital admission for patients with Chronic Obstructive Pulmonary Disease (COPD).\n",
    "By implementing machine learning, we collect patient severity levels on symptoms and medical history that can assist healthcare professionals\n",
    "in decision-making.\n",
    "\n",
    "## Goals:\n",
    "1. Preprocess the dataset to make it ready for machine learning.\n",
    "2. Train a logistic regression model to predict hospital admissions.\n",
    "3. Evaluate the model using metrics such as precision, recall, F1-score, and ROC-AUC.\n",
    "4. Save the trained model for deployment.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df3d8ecb410f3b6f",
   "metadata": {},
   "source": [
    "## PART 1: Import Libraries\n",
    "Load all needed libraries for app to function"
   ]
  },
  {
   "cell_type": "code",
   "id": "3df6b1ce97f8c8a0",
   "metadata": {},
   "source": [
    "# Importing necessary libraries\n",
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import confusion_matrix, classification_report, roc_auc_score\n",
    "import joblib\n"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "8c82004bae7d03be",
   "metadata": {},
   "source": [
    "## PART 2: Load the Dataset\n",
    "This part loads the preprocessed dataset and displays the first five rows to view the current data structure.\n"
   ]
  },
  {
   "cell_type": "code",
   "id": "58d231ff72b5bb39",
   "metadata": {},
   "source": [
    "# Dynamically locate the project root and construct the file path\n",
    "notebook_dir = os.path.abspath(os.getcwd())\n",
    "base_dir = os.path.abspath(os.path.join(notebook_dir, '..'))  # Go up one directory\n",
    "data_file = os.path.join(base_dir, \"data\", \"copd_data_preprocessed.csv\")\n",
    "\n",
    "# Load the data\n",
    "try:\n",
    "    df = pd.read_csv(data_file)\n",
    "    print(\"Data loaded successfully!\")\n",
    "    display(df.head())\n",
    "except FileNotFoundError as e:\n",
    "    print(f\"Error: {e}\")\n",
    "    print(f\"Ensure the file exists at: {data_file}\")\n"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "1134efed7abcd638",
   "metadata": {},
   "source": [
    "## PART 3: Preprocess the Data\n",
    "This part preprocesses the dataset, including splitting into training, testing sets, and scaling the fields to ingest into the machine learning model.\n"
   ]
  },
  {
   "cell_type": "code",
   "id": "6231094e00250003",
   "metadata": {},
   "source": [
    "# Splitting features and target variable\n",
    "X = df.drop(columns=[\"Hospital_Admission\"])  # Replace with actual target column name\n",
    "y = df[\"Hospital_Admission\"]\n",
    "\n",
    "# Train-test split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Standardizing the features\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "print(\"Data preprocessing completed.\")\n"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "fc91a36537df95fb",
   "metadata": {},
   "source": [
    "## PART 4: Train the Model\n",
    "This part includes training the logistic regression model on the provided dataset and prepares it for analysis.\n"
   ]
  },
  {
   "cell_type": "code",
   "id": "934a53c036b1f8f",
   "metadata": {},
   "source": [
    "# Initializing and training the logistic regression model\n",
    "model = LogisticRegression(\n",
    "    class_weight=\"balanced\",  # Handling imbalanced data\n",
    "    max_iter=5000,\n",
    "    solver=\"liblinear\"\n",
    ")\n",
    "model.fit(X_train_scaled, y_train)\n",
    "\n",
    "print(\"Model training completed.\")\n"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "bd9ca7d790f2a6cd",
   "metadata": {},
   "source": [
    "## PART 5: Evaluate the Model\n",
    "This part evaluates the model using accuracy, precision, recall, and F1-score metrics. It also generates a confusion matrix and its values.\n"
   ]
  },
  {
   "cell_type": "code",
   "id": "6e5833d16b7d49b7",
   "metadata": {},
   "source": [
    "# Making predictions\n",
    "y_pred = model.predict(X_test_scaled)\n",
    "y_proba = model.predict_proba(X_test_scaled)[:, 1]  # Probability scores\n",
    "\n",
    "# Confusion matrix\n",
    "conf_matrix = confusion_matrix(y_test, y_pred)\n",
    "print(\"Confusion Matrix:\")\n",
    "print(conf_matrix)\n",
    "\n",
    "# Classification report\n",
    "class_report = classification_report(y_test, y_pred)\n",
    "print(\"\\nClassification Report:\")\n",
    "print(class_report)\n",
    "\n",
    "# ROC-AUC Score\n",
    "roc_auc = roc_auc_score(y_test, y_proba)\n",
    "print(f\"ROC-AUC Score: {roc_auc}\")\n"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "3ab74a1f108d9ce1",
   "metadata": {},
   "source": [
    "## PART 6: Save the Model\n",
    "Ready the model by saving for future deployment."
   ]
  },
  {
   "cell_type": "code",
   "id": "13bd8af3d724c149",
   "metadata": {},
   "source": [
    "# Saving the trained model for deployment\n",
    "model_file = os.path.join(base_dir, \"model\", \"logistic_model.pkl\")\n",
    "\n",
    "try:\n",
    "    os.makedirs(os.path.join(base_dir, \"model\"), exist_ok=True)  # Ensure the directory exists\n",
    "    joblib.dump(model, model_file)\n",
    "    print(f\"Model saved at: {model_file}\")\n",
    "except Exception as e:\n",
    "    print(f\"Error saving model: {e}\")\n"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "4d8a84303887ddd2",
   "metadata": {},
   "source": [
    "## PART 7: Load Model\n",
    "Test that the model is functional after saving and does not require retraining.\n"
   ]
  },
  {
   "cell_type": "code",
   "id": "af8b785426b5d9ed",
   "metadata": {},
   "source": [
    "# Loading the saved model\n",
    "try:\n",
    "    loaded_model = joblib.load(model_file)\n",
    "    test_proba = loaded_model.predict_proba(X_test_scaled)[:, 1]\n",
    "    print(\"Model loaded successfully.\")\n",
    "    print(f\"Sample Prediction Probability: {test_proba[:5]}\")\n",
    "except Exception as e:\n",
    "    print(f\"Error loading model: {e}\")\n"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## Part 8: Visit the UI on Heroku\n",
    "https://copd-hospital-assessment-2902c73cfbc3.herokuapp.com/"
   ],
   "id": "12a8f8d45842fd5b"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
